import os
import re
import sys
import asyncio
import random
from typing import List, Optional, Any
from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.orm import Session
import google.generativeai as genai
from dotenv import load_dotenv

from app.schemas import ChatMessage, ChatResponse, ChatHistoryItem
from app.database import get_db
from app import models
from app.deps import get_current_user

load_dotenv()

router = APIRouter()

# Configure Gemini
api_key = os.getenv("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.0-flash') # Updated to 2.0-flash
else:
    model = None

@router.get("/history/{session_id}", response_model=List[ChatHistoryItem])
async def get_chat_history(
    session_id: str, 
    db: Session = Depends(get_db), 
    user: models.User = Depends(get_current_user)
):
    history = db.query(models.ChatMessage).filter(
        models.ChatMessage.user_id == user.id,
        models.ChatMessage.session_id == session_id
    ).order_by(models.ChatMessage.created_at.asc()).all()
    return history

@router.post("", response_model=ChatResponse)
async def chat_endpoint(
    chat_msg: ChatMessage, 
    db: Session = Depends(get_db),
    user: models.User = Depends(get_current_user)
):
    if not model:
        return ChatResponse(response="API Key not configured. Please set GEMINI_API_KEY in backend/.env")
    
    # Save user message to DB
    user_msg_db = models.ChatMessage(
        user_id=user.id,
        session_id=chat_msg.session_id,
        role="user",
        content=chat_msg.message,
        image_url=chat_msg.image_url,
        mission_id=chat_msg.current_mission_id
    )
    db.add(user_msg_db)
    db.commit()

    # Fetch User Settings
    settings = db.query(models.UserSettings).filter(models.UserSettings.user_id == user.id).first()
    if not settings:
        settings = models.UserSettings(user_id=user.id, learning_mode="supportive")
        db.add(settings)
        db.commit()
    
    mode = settings.learning_mode
    
    # Context gathering
    mission_context = ""
    if chat_msg.current_mission_id:
        mission = db.query(models.PlanItem).filter(models.PlanItem.id == chat_msg.current_mission_id).first()
        if mission:
            mission_context = f"\n\n[ç¾åœ¨å–ã‚Šçµ„ã‚“ã§ã„ã‚‹ãƒŸãƒƒã‚·ãƒ§ãƒ³: {mission.content}]\n"
            mission_context += f"ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç¾åœ¨ã®ç†è§£åº¦ã‚¹ã‚³ã‚¢: {mission.understanding_score}/100\n"
            mission_context += "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã“ã®ãƒŸãƒƒã‚·ãƒ§ãƒ³ã®å†…å®¹ã‚’ç†è§£ã—ã¦ã„ã‚‹ã‹ã€å¯¾è©±ã‚’é€šã˜ã¦è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"
    
    app_guide = (
        "\nã€ã‚¢ãƒ—ãƒªã®æ“ä½œã‚¬ã‚¤ãƒ‰ã€‘\n"
        "- ã‚¹ãƒãƒ›é€£æº: å·¦ä¸‹ã®ã€ç”»åƒã‚’åŒæœŸã€ã‹ã‚‰QRã‚’è¡¨ç¤ºã—ã¦ã‚¹ãƒãƒ›ã§æ’®å½±ãƒ»é€ä¿¡ã™ã‚‹ã¨ã€ç”»é¢ã«ç”»åƒãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚\n"
        "- ãƒŸãƒƒã‚·ãƒ§ãƒ³ç™»éŒ²: AIã®å›ç­”ã®ä¸‹ã«ã‚ã‚‹ã€ğŸ“… ã“ã®å†…å®¹ã‚’ãƒŸãƒƒã‚·ãƒ§ãƒ³ã«ç™»éŒ²ã€ãƒœã‚¿ãƒ³ã‹ã‚‰å­¦ç¿’è¨ˆç”»ã¨ã—ã¦ä¿å­˜ã§ãã¾ã™ã€‚\n"
        "- ãƒ¡ãƒ¢æ©Ÿèƒ½: å³ä¸‹ã®ãƒšãƒ³ã‚¢ã‚¤ã‚³ãƒ³ï¼ˆé»„è‰²ï¼‰ã‹ã‚‰ã‚¯ã‚¤ãƒƒã‚¯ãƒ¡ãƒ¢ã‚’ä½œæˆãƒ»ç®¡ç†ã§ãã¾ã™ã€‚\n"
        "- å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰: å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€æ”¯æ´ã€ã¨ã€å—é¨“ã€ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‰ã‚Œã¾ã™ã€‚\n"
        "- ãƒŸãƒƒã‚·ãƒ§ãƒ³å®Œäº†: ç†è§£åº¦ã‚¹ã‚³ã‚¢ãŒç›®æ¨™ï¼ˆå—é¨“:80%, æ”¯æ´:60%ï¼‰ã‚’è¶…ãˆã‚‹ã¨ã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ã€å®Œäº†ã€ãƒœã‚¿ãƒ³ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã™ã€‚\n"
        "æ“ä½œã«é–¢ã™ã‚‹è³ªå•ã«ã¯ã€ã“ã‚Œã‚‰ã®æƒ…å ±ã«åŸºã¥ã„ã¦å®¶åº­æ•™å¸«ã¨ã—ã¦å„ªã—ãç­”ãˆã¦ãã ã•ã„ã€‚"
    )

    # Define Persona and Rules based on Mode (Mission Focus vs Free Talk)
    if chat_msg.current_mission_id:
        # Mission Focus Mode: Coach / Evaluator
        if mode == "exam":
            system_instr = (
                "ã‚ãªãŸã¯é€²å­¦å¡¾ã®ãƒˆãƒƒãƒ—è¬›å¸«ã§ã™ï¼ˆå®Ÿç¸¾è©•ä¾¡ï¼šå—é¨“ãƒ¢ãƒ¼ãƒ‰ï¼‰ã€‚\n"
                "ç¾åœ¨å–ã‚Šçµ„ã‚“ã§ã„ã‚‹ãƒŸãƒƒã‚·ãƒ§ãƒ³ã®é€²æ—å ±å‘Šã‚’å—ã‘ã€å³æ ¼ã«å¯©æŸ»ã—ã¦ãã ã•ã„ã€‚\n"
                "ã€è©•ä¾¡åŸºæº–ã€‘\n"
                "- è«–ç†æ€§ã€æ­£ç¢ºæ€§ã€ãŠã‚ˆã³ã€è‡ªåˆ†ã®è¨€è‘‰ã€ã§ã®èª¬æ˜èƒ½åŠ›ã‚’æœ€é‡è¦–ã—ã¾ã™ã€‚\n"
                "- å—é¨“ãƒ¬ãƒ™ãƒ«ã§è‡ªåŠ›ã§è§£ã‘ã‚‹ã¨ç¢ºä¿¡ã§ãã‚‹ã¾ã§å³ã—ãè©•ä¾¡ã—ã¦ãã ã•ã„ã€‚\n"
                "- å ±å‘Šã®ä¸­ã«æ•°å€¤ã‚„å…·ä½“çš„ãªæˆæœãŒã‚ã‚Œã°ã€å›ç­”ã®ã©ã“ã‹ã« [[RESULT: ã‚µãƒãƒªãƒ¼]] (ä¾‹: [[RESULT: 10å•ä¸­8å•æ­£è§£]]) ã‚’å«ã‚ã¦ãã ã•ã„ã€‚\n"
                "- å›ç­”ã®æœ€å¾Œã«å¿…ãš [[SCORE: æ•°å€¤]] (0-100) ã‚’ä»˜ä¸ã—ã¦ãã ã•ã„ã€‚"
            )
        else:
            system_instr = (
                "ã‚ãªãŸã¯å„ªã—ã„ã‚³ãƒ¼ãƒã§ã™ï¼ˆå®Ÿç¸¾è©•ä¾¡ï¼šæ”¯æ´ãƒ¢ãƒ¼ãƒ‰ï¼‰ã€‚\n"
                "ç¾åœ¨å–ã‚Šçµ„ã‚“ã§ã„ã‚‹ãƒŸãƒƒã‚·ãƒ§ãƒ³ã®é€²æ—å ±å‘Šã‚’å—ã‘ã€åŠªåŠ›ã‚’è¤’ã‚ã¤ã¤ç†è§£åº¦ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
                "ã€è©•ä¾¡åŸºæº–ã€‘\n"
                "- åŠªåŠ›ãƒ»å‚åŠ ã‚’é«˜ãè©•ä¾¡ã—ã¾ã™ã€‚è‡ªåˆ†ã®è¨€è‘‰ã§èª¬æ˜ã§ããŸã‚‰ã‚¹ã‚³ã‚¢ã‚’ä¸Šã’ã¦ãã ã•ã„ã€‚\n"
                "- å®Œäº†é–¾å€¤ï¼ˆ60%ï¼‰ã‚’ç›®æŒ‡ã—ã¦ã€å„ªã—ãã‚¬ã‚¤ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n"
                "- å ±å‘Šã®ä¸­ã«æ•°å€¤ã‚„å…·ä½“çš„ãªæˆæœãŒã‚ã‚Œã°ã€å›ç­”ã®ã©ã“ã‹ã« [[RESULT: ã‚µãƒãƒªãƒ¼]] (ä¾‹: [[RESULT: è‹±å˜èªã‚’3ã¤è¦šãˆãŸ]]) ã‚’å«ã‚ã¦ãã ã•ã„ã€‚\n"
                "- å›ç­”ã®æœ€å¾Œã«å¿…ãš [[SCORE: æ•°å€¤]] (0-100) ã‚’ä»˜ä¸ã—ã¦ãã ã•ã„ã€‚"
            )
    else:
        # Free Talk Mode: Learning Assistant / Mentor
        if mode == "exam":
            system_instr = (
                "ã‚ãªãŸã¯çŸ¥çš„ãªå­¦ç¿’ãƒ¡ãƒ³ã‚¿ãƒ¼ã§ã™ï¼ˆãƒ•ãƒªãƒ¼ãƒˆãƒ¼ã‚¯ï¼šå—é¨“ãƒ¢ãƒ¼ãƒ‰ï¼‰ã€‚\n"
                "ç”Ÿå¾’ã®ç–‘å•ã«å¯¾ã—ã€å­¦è¡“çš„ãƒ»è«–ç†çš„ãªèƒŒæ™¯ã‚’å«ã‚ã¦è©³ç´°ã«è§£èª¬ã—ã¦ãã ã•ã„ã€‚\n"
                "ã“ã®ãƒ¢ãƒ¼ãƒ‰ã§ã¯é€²æ—è©•ä¾¡ï¼ˆã‚¹ã‚³ã‚¢ä»˜ä¸ï¼‰ã¯ã›ãšã€ç´”ç²‹ãªå­¦ç¿’ç›¸è«‡ã«ä¹—ã£ã¦ãã ã•ã„ã€‚\n"
                "â€»ã‚¹ã‚³ã‚¢ä»˜ä¸è¨˜æ³• [[SCORE: XX]] ã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚"
            )
        else:
            system_instr = (
                "ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ã„å­¦ç¿’ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã§ã™ï¼ˆãƒ•ãƒªãƒ¼ãƒˆãƒ¼ã‚¯ï¼šæ”¯æ´ãƒ¢ãƒ¼ãƒ‰ï¼‰ã€‚\n"
                "ã€Œã‚ã‹ã‚‰ãªã„ã€ã¨ã„ã†æ°—æŒã¡ã‚’å¤§åˆ‡ã«ã—ã€å™›ã¿ç •ã„ã¦å„ªã—ãæ•™ãˆã¦ã‚ã’ã¦ãã ã•ã„ã€‚\n"
                "ã“ã®ãƒ¢ãƒ¼ãƒ‰ã§ã¯é€²æ—è©•ä¾¡ï¼ˆã‚¹ã‚³ã‚¢ä»˜ä¸ï¼‰ã¯ã›ãšã€æ¥½ã—ãå¯¾è©±ã—ã¦ãã ã•ã„ã€‚\n"
                "â€»ã‚¹ã‚³ã‚¢ä»˜ä¸è¨˜æ³• [[SCORE: XX]] ã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚"
            )

    system_instr += app_guide

    # Fetch recent history for context (last 10 messages)
    history_text = ""
    if chat_msg.session_id:
        recent_history = db.query(models.ChatMessage).filter(
            models.ChatMessage.user_id == user.id,
            models.ChatMessage.session_id == chat_msg.session_id
        ).order_by(models.ChatMessage.created_at.desc()).limit(11).all()
        history_text = "\n".join([f"{m.role}: {m.content}" for m in reversed(recent_history)])
    
    # Prepare contents for Gemini
    content_parts = [system_instr + mission_context]
    if history_text:
        content_parts.append(f"\n\nã€ã“ã‚Œã¾ã§ã®ä¼šè©±ã€‘\n{history_text}")
    
    # Add current image if available
    if chat_msg.image_url:
        try:
            filename = os.path.basename(chat_msg.image_url)
            local_path = os.path.join("uploads", filename)
            
            if os.path.exists(local_path):
                import PIL.Image
                img = PIL.Image.open(local_path)
                content_parts.append(img)
            else:
                print(f"Warning: Image path not found: {local_path}", file=sys.stderr)
        except Exception as e:
            print(f"Error loading image: {e}", file=sys.stderr)

    max_retries = 3
    for attempt in range(max_retries):
        try:
            # Pass the list of parts to Gemini
            response = await model.generate_content_async(content_parts)
            raw_text = response.text
            
            # Extract result
            res_val = None
            res_match = re.search(r"\[\[RESULT:\s*(.*?)\]\]", raw_text)
            if res_match:
                res_val = res_match.group(1).strip()
                clean_text = re.sub(r"\[\[RESULT:\s*.*?\]\]", "", raw_text).strip()
            else:
                clean_text = raw_text

            # Extract score
            score = None
            score_match = re.search(r"\[\[SCORE:\s*(\d+)\]\]", clean_text)
            if score_match:
                score = int(score_match.group(1))
                clean_text = re.sub(r"\[\[SCORE:\s*\d+\]\]", "", clean_text).strip()
            
            # Save assistant response to DB
            assistant_msg_db = models.ChatMessage(
                user_id=user.id,
                session_id=chat_msg.session_id,
                role="assistant",
                content=clean_text,
                understanding_score=score,
                mission_id=chat_msg.current_mission_id
            )
            db.add(assistant_msg_db)
            db.commit()

            # Update DB if score or result found and mission exists
            if (score is not None or res_val is not None) and chat_msg.current_mission_id:
                mission = db.query(models.PlanItem).filter(models.PlanItem.id == chat_msg.current_mission_id).first()
                if mission:
                    if score is not None:
                        mission.understanding_score = score
                    if res_val is not None:
                        mission.last_result = res_val
                    db.commit()

            return ChatResponse(response=clean_text, understanding_score=score, extracted_result=res_val)
            
        except Exception as e:
            error_str = str(e)
            print(f"Gemini API Error (Attempt {attempt+1}): {e}", file=sys.stderr)
            
            if "429" in error_str and attempt < max_retries - 1:
                wait_time = 2 * (2 ** attempt) + random.uniform(0, 1)
                await asyncio.sleep(wait_time)
                continue
            
            if attempt == max_retries - 1:
                raise HTTPException(status_code=500, detail=f"AIã¨ã®å¯¾è©±ã«å¤±æ•—ã—ã¾ã—ãŸ: {error_str}")
